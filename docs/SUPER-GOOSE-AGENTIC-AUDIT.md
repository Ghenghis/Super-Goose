# Super-Goose Full Agentic Audit â€” End-to-End Analysis

**Date:** 2026-02-14
**Scope:** Complete ZIP audit + uploaded artifacts + agentic self-update architecture
**Focus:** Maximum agentic autonomy, inter-agent communication, self-healing rebuild

---

## 1. CURRENT STATE AUDIT â€” What Exists

### 1.1 Backend (Rust) â€” STRONG

| System | Files | Tests | Status |
|--------|-------|-------|--------|
| Agent Core System | 11 | 87 | âœ… Solid â€” 6 cores + selector + registry |
| Learning Engine | 4 modules | 52 | âœ… Solid â€” ExperienceStore, SkillLibrary, InsightExtractor, ReflectionStore |
| OTA Self-Build | 14 files | 198 | âœ… Solid â€” StateSaver â†’ SelfBuilder â†’ BinarySwapper â†’ HealthChecker â†’ Rollback |
| Self-Improvement Pipeline | 7 modules | â€” | âœ… Exists â€” ImprovementPlanner, CodeApplier, SandboxRunner, TestRunner, PolicyEngine, SafetyEnvelope, AutoImproveScheduler |
| Autonomous Daemon | 8 files | 86 | âœ… Solid â€” TaskScheduler, BranchManager, ReleaseManager, Failsafe, AuditLog |
| TimeWarp Event Store | 1 | 8 | âœ… Working â€” SQLite event + branch tables |
| Compaction Manager | 1 | â€” | âœ… Working â€” context window management |
| Guardrails Engine | 6 detectors | â€” | âœ… Working â€” PII, injection, jailbreak, secrets, topics, keywords |
| API Routes | 28 modules | 34 | âœ… Extensive â€” SSE streaming, REST, settings broadcast |
| MCP Client | goose-mcp | â€” | âœ… Working â€” stdio + streamable_http |
| ACP Client | goose-acp | â€” | âœ… Exists â€” agent-to-agent protocol stub |

### 1.2 Frontend (React/TypeScript) â€” STRONG but gaps

| System | Components | Status |
|--------|-----------|--------|
| Super-Goose 8-Panel Sidebar | 8 panels + 6 shared | âœ… Working |
| Feature Panels | 4 (Budget, Critic, Guardrails, Reflexion) | âœ… API-wired |
| TimeWarp | 8 components + hook | âœ… Working |
| Pipeline Visualization | 4 components | âœ… Working |
| Studios | 6 tabs | âš ï¸ 4/6 "Coming Soon" stubs |
| Enterprise Settings | 6 panels | âœ… Wired |
| CLI Integration | 3 components | âœ… Working |
| Design System | sg-* tokens (60 vars, 255 lines) | âœ… Scoped |

### 1.3 Tests â€” EXCELLENT

| Suite | Result |
|-------|--------|
| Vitest | 2,633 passed, 3 skipped, 0 failed |
| Playwright E2E | 291 passed, 68 skipped, 0 failed |
| tsc --noEmit | CLEAN |
| cargo check | CLEAN (0 errors, 0 warnings) |
| Rust unit | 87 + 198 + 86 + 52 + 8 + 34 = 465+ all passing |

### 1.4 Documentation â€” EXTENSIVE

70+ markdown files across docs, guides, archive/sessions, archive/plans. Architecture doc is comprehensive. Multiple session reports show iterative progress.

---

## 2. CRITICAL GAPS â€” What's Missing

### 2.1 The Core Problem You're Facing

```
PROBLEM: Super-Goose needs Goose (the LLM agent session) to be RUNNING to do anything.
         But Super-Goose also needs to REBUILD ITSELF, which kills the running session.
         How does the agent survive its own rebuild?
```

This is the **Theseus's Ship problem for AI agents** â€” can the agent replace itself while remaining continuously operational?

### 2.2 Gap Matrix

| # | Gap | Severity | Where | Impact |
|---|-----|----------|-------|--------|
| G1 | **No Conductor Process** â€” nothing survives rebuild | ğŸ”´ CRITICAL | Architecture | Agent dies when app rebuilds |
| G2 | **No Inter-Agent Message Bus** â€” agents can't talk to each other | ğŸ”´ CRITICAL | `crates/goose/src/` | No team coordination |
| G3 | **No Agent Registry/Discovery** â€” agents don't know about each other | ğŸ”´ CRITICAL | `crates/goose-server/` | Can't route messages |
| G4 | **No Persistent Task Queue** â€” tasks lost on restart | ğŸ”´ CRITICAL | `crates/goose/src/autonomous/` | Work lost on rebuild |
| G5 | **Conscious backend routes missing** | ğŸŸ¡ HIGH | `goose-server/routes/` | Voice system disconnected |
| G6 | **AG-UI POST endpoints not wired** | ğŸŸ¡ HIGH | `goose-server/routes/` | UI can't send tool results back |
| G7 | **Studio stubs violate no-placeholder rule** | ğŸŸ¡ HIGH | `ui/desktop/src/` | 4 "Coming Soon" panels |
| G8 | **GPU Jobs backend missing** | ğŸŸ¡ HIGH | `goose-server/routes/` | Launch button does nothing |
| G9 | **13 bundled extensions not implemented** | ğŸŸ¡ MEDIUM | `goose-mcp/` | Declared but not real |
| G10 | **API Key vault missing** | ğŸŸ¡ MEDIUM | `goose-server/routes/` | Can't manage keys from UI |
| G11 | **External Python deps not installed** | ğŸŸ¡ MEDIUM | `scripts/` | Conscious/tools won't start |
| G12 | **Shared memory between agents** | ğŸŸ¡ MEDIUM | `crates/goose/src/` | Per-agent only, no team memory |
| G13 | **Agent wake-up/sleep lifecycle** | ğŸŸ¡ MEDIUM | `crates/goose/src/` | No way to wake sleeping agents |
| G14 | **38 uncommitted files** | ğŸŸ  DO NOW | `feat/resizable-layout` | Risk of losing work |

---

## 3. THE CONDUCTOR ARCHITECTURE â€” Solving Self-Update

This is the answer to your core question: "How does Goose continue without user interaction when the project needs rebuilding?"

### 3.1 The Problem in Detail

```
Current Flow (BROKEN):
  User â†’ npm run start-gui â†’ Electron + goosed starts â†’ Agent session active
  Agent decides to self-improve â†’ cargo build â†’ new binary ready
  ??? How to swap? Electron is running. goosed is running. Agent is mid-session.
  If you kill goosed â†’ agent session dies â†’ no one to verify the new build
  If you kill Electron â†’ UI dies â†’ user can't see what's happening
```

### 3.2 The Solution: Three-Layer Conductor Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 0: THE CONDUCTOR (Never Dies)                                â”‚
â”‚ A tiny, persistent daemon that outlives everything else.            â”‚
â”‚ Written in Rust. Compiled once. Runs as a system service.           â”‚
â”‚                                                                     â”‚
â”‚ Responsibilities:                                                   â”‚
â”‚ â€¢ Start/stop/restart goosed (the Rust backend)                     â”‚
â”‚ â€¢ Start/stop/restart Electron (the GUI)                            â”‚
â”‚ â€¢ Maintain the persistent task queue (SQLite)                      â”‚
â”‚ â€¢ Maintain the agent message bus (Unix socket / named pipe)        â”‚
â”‚ â€¢ Health check all children every 5 seconds                        â”‚
â”‚ â€¢ Route inter-agent messages even during rebuilds                  â”‚
â”‚ â€¢ Accept commands via IPC (socket/pipe) from goosed or Electron    â”‚
â”‚ â€¢ Log everything to a crash-safe log file                          â”‚
â”‚                                                                     â”‚
â”‚ THE CONDUCTOR IS NEVER REBUILT BY THE AGENT.                       â”‚
â”‚ It is updated separately, manually, via a simple binary swap.       â”‚
â”‚ It is ~500 lines of Rust. It has zero LLM logic.                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                        â”‚
              â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: goosed          â”‚  â”‚ LAYER 2: Electron GUI               â”‚
â”‚ (The Rust backend)       â”‚  â”‚ (The React frontend)                â”‚
â”‚                          â”‚  â”‚                                     â”‚
â”‚ â€¢ Agent sessions         â”‚  â”‚ â€¢ 8-panel sidebar                   â”‚
â”‚ â€¢ LLM communication      â”‚  â”‚ â€¢ Mission control                   â”‚
â”‚ â€¢ MCP tool execution     â”‚  â”‚ â€¢ TimeWarp, Studios, etc.           â”‚
â”‚ â€¢ OTA self-build         â”‚  â”‚ â€¢ Connects to goosed via HTTP/SSE   â”‚
â”‚ â€¢ Learning engine        â”‚  â”‚ â€¢ Connects to Conductor via IPC     â”‚
â”‚                          â”‚  â”‚                                     â”‚
â”‚ CAN BE KILLED + RESTARTEDâ”‚  â”‚ CAN BE KILLED + RESTARTED          â”‚
â”‚ by the Conductor         â”‚  â”‚ by the Conductor                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Self-Update Sequence (The Full Flow)

```
SELF-UPDATE SEQUENCE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. DETECT
   Agent (via goosed) identifies an improvement opportunity:
   â€¢ InsightExtractor finds a failure pattern
   â€¢ AutoImproveScheduler triggers a cycle
   â€¢ User requests /self-improve

2. PLAN
   ImprovementPlanner creates an ImprovementPlan:
   â€¢ What files to change
   â€¢ Expected outcome
   â€¢ Risk assessment
   â€¢ Rollback strategy

3. SAVE STATE â†’ CONDUCTOR
   Agent sends state snapshot to the Conductor:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ConductorMessage::SaveState {           â”‚
   â”‚   task_queue: Vec<PendingTask>,         â”‚
   â”‚   agent_states: Vec<AgentSnapshot>,     â”‚
   â”‚   pending_messages: Vec<AgentMessage>,  â”‚
   â”‚   active_sessions: Vec<SessionId>,      â”‚
   â”‚   improvement_plan: ImprovementPlan,    â”‚
   â”‚ }                                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Conductor writes this to SQLite (crash-safe, WAL mode).

4. APPLY CODE CHANGES (in sandbox)
   CodeApplier writes changes to a STAGING COPY of the source:
   â€¢ /home/user/.goose/staging/ â† copy of source
   â€¢ Changes applied here, NOT to the live source
   â€¢ Live goosed continues running normally

5. BUILD NEW BINARY (from staging)
   SelfBuilder runs: cargo build -p goose-server --release
   â€¢ Builds from /home/user/.goose/staging/
   â€¢ Output: /home/user/.goose/staging/target/release/goosed-new
   â€¢ Live system is STILL RUNNING during this build

6. TEST NEW BINARY (in isolation)
   TestRunner launches the new binary on a DIFFERENT PORT:
   â€¢ goosed-new --port 3285 (staging port, not 3284)
   â€¢ Runs health check against http://localhost:3285/status
   â€¢ Runs smoke tests against the new binary
   â€¢ Runs unit tests: cargo test
   â€¢ If ANY test fails â†’ ABORT, discard staging, log failure

7. SWAP â€” Conductor orchestrates the hot-swap:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ a) Conductor tells Electron: "entering maintenance mode"    â”‚
   â”‚    â†’ UI shows "Upgrading... please wait" overlay            â”‚
   â”‚    â†’ UI stays open, shows progress bar                      â”‚
   â”‚                                                              â”‚
   â”‚ b) Conductor tells goosed: "drain and shutdown"              â”‚
   â”‚    â†’ goosed stops accepting new requests                     â”‚
   â”‚    â†’ goosed finishes any in-flight LLM calls (timeout: 30s) â”‚
   â”‚    â†’ goosed serializes all sessions to SQLite                â”‚
   â”‚    â†’ goosed exits cleanly                                    â”‚
   â”‚                                                              â”‚
   â”‚ c) Conductor performs binary swap:                            â”‚
   â”‚    â†’ mv goosed goosed-backup                                 â”‚
   â”‚    â†’ mv goosed-new goosed                                    â”‚
   â”‚                                                              â”‚
   â”‚ d) Conductor starts NEW goosed:                              â”‚
   â”‚    â†’ goosed starts on port 3284                              â”‚
   â”‚    â†’ goosed reads saved state from SQLite                    â”‚
   â”‚    â†’ goosed restores sessions, agent states, pending tasks   â”‚
   â”‚                                                              â”‚
   â”‚ e) Conductor health-checks new goosed:                       â”‚
   â”‚    â†’ GET http://localhost:3284/status                        â”‚
   â”‚    â†’ If healthy â†’ tell Electron "maintenance complete"       â”‚
   â”‚    â†’ Electron reconnects SSE, resumes normal operation       â”‚
   â”‚                                                              â”‚
   â”‚ f) If new goosed FAILS to start:                             â”‚
   â”‚    â†’ mv goosed goosed-failed                                 â”‚
   â”‚    â†’ mv goosed-backup goosed                                 â”‚
   â”‚    â†’ Start old goosed (known-good)                           â”‚
   â”‚    â†’ Tell Electron "rollback complete, upgrade failed"       â”‚
   â”‚    â†’ Log failure, apply exponential backoff to next attempt  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

8. RESUME
   New goosed is running with all state restored.
   Agent picks up where it left off.
   If the improvement was successful, ExperienceStore records success.
   If the improvement caused issues, next cycle can self-revert.

DOWNTIME: ~5-15 seconds (drain + swap + startup + health check)
USER EXPERIENCE: UI stays open, shows progress, auto-reconnects
AGENT EXPERIENCE: Seamless â€” state restored, tasks resume
```

### 3.4 Conductor Implementation

```
NEW FILES NEEDED:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
crates/goose-conductor/
  Cargo.toml
  src/
    main.rs              # Entry point, signal handlers, service registration
    child_manager.rs     # Start/stop/restart goosed + Electron
    health_checker.rs    # Periodic health checks with circuit breaker
    ipc_server.rs        # Unix socket (Linux/Mac) / Named pipe (Windows)
    state_store.rs       # SQLite state persistence (task queue, agent state)
    message_bus.rs       # Inter-agent message routing (survives rebuilds)
    log_manager.rs       # Crash-safe structured logging
    config.rs            # Conductor configuration

ESTIMATED SIZE: ~1,200 lines of Rust
DEPENDENCIES: tokio, sqlx, serde, serde_json
NO LLM DEPENDENCIES. NO MCP. NO COMPLEX LOGIC.
The Conductor is deliberately dumb â€” it just manages processes.
```

### 3.5 Why This Architecture Works

| Problem | Solution |
|---------|----------|
| Agent dies on rebuild | Conductor survives, restarts goosed with state |
| Tasks lost on restart | Persistent task queue in Conductor's SQLite |
| Messages lost on restart | Message bus in Conductor, queues until recipient alive |
| UI disconnects | Electron stays open, reconnects to new goosed |
| Bad build deployed | Health check fails â†’ automatic rollback to backup |
| Agent can't start next cycle | Conductor's task queue preserves the plan |
| Multiple rebuilds in a row | Each one follows the same swap protocol |
| Conductor itself crashes | Registered as system service, OS restarts it |

---

## 4. INTER-AGENT COMMUNICATION SYSTEM

### 4.1 The Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     CONDUCTOR            â”‚
                    â”‚     Message Bus          â”‚
                    â”‚     (SQLite-backed)      â”‚
                    â”‚                          â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                    â”‚  â”‚ message_queue    â”‚    â”‚
                    â”‚  â”‚ (persistent)     â”‚    â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                    â”‚  â”‚ agent_registry   â”‚    â”‚
                    â”‚  â”‚ (who's online)   â”‚    â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                    â”‚  â”‚ topic_subscriptionsâ”‚   â”‚
                    â”‚  â”‚ (pub/sub)        â”‚    â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Architect â”‚   â”‚  Developer  â”‚   â”‚  QA Agent           â”‚
    â”‚ Agent     â”‚   â”‚  Agent      â”‚   â”‚                     â”‚
    â”‚           â”‚   â”‚             â”‚   â”‚  (currently offline) â”‚
    â”‚ ONLINE    â”‚   â”‚ ONLINE      â”‚   â”‚  OFFLINE â€” has 3    â”‚
    â”‚           â”‚   â”‚             â”‚   â”‚  queued messages     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Message Types

```rust
// crates/goose/src/agent_bus/messages.rs

/// Every message between agents follows this format
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentMessage {
    pub id: Uuid,
    pub from: AgentId,
    pub to: MessageTarget,        // specific agent, role, or broadcast
    pub channel: MessageChannel,  // direct, team, broadcast, system
    pub priority: Priority,       // critical, high, normal, low
    pub payload: MessagePayload,
    pub reply_to: Option<Uuid>,   // for conversation threading
    pub created_at: DateTime<Utc>,
    pub expires_at: Option<DateTime<Utc>>,
    pub delivered: bool,
    pub acknowledged: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MessageTarget {
    Agent(AgentId),               // direct message to specific agent
    Role(AgentRole),              // message to whoever fills this role
    Team(TeamId),                 // message to all agents in a team
    Broadcast,                    // message to all online agents
    Topic(String),                // pub/sub topic
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MessagePayload {
    // Task coordination
    TaskAssignment { task: TaskSpec, deadline: Option<DateTime<Utc>> },
    TaskUpdate { task_id: Uuid, status: TaskStatus, details: String },
    TaskComplete { task_id: Uuid, result: TaskResult, artifacts: Vec<Artifact> },

    // Knowledge sharing
    CodeChange { files: Vec<FileDiff>, reason: String },
    TestResult { suite: String, passed: u32, failed: u32, details: Vec<TestDetail> },
    Insight { category: InsightCategory, content: String, confidence: f32 },
    MemoryShare { key: String, value: serde_json::Value },

    // Coordination
    PlanProposal { plan: Plan, needs_approval: bool },
    PlanApproval { plan_id: Uuid, approved: bool, feedback: Option<String> },
    StatusRequest,
    StatusResponse { status: AgentStatus, current_task: Option<String> },
    HelpRequest { problem: String, context: Vec<String> },
    HelpResponse { suggestion: String, confidence: f32 },

    // Lifecycle
    WakeUp { reason: String },           // â† WAKE UP AN OFFLINE AGENT
    GoingOffline { reason: String },
    ComingOnline { capabilities: Vec<String> },
    Heartbeat { load: f32 },

    // System
    BuildStarting { version: String },
    BuildComplete { version: String, success: bool },
    RollbackRequired { reason: String },

    // Free-form (agents can define their own protocols)
    Custom { event_type: String, data: serde_json::Value },
}
```

### 4.3 Agent Wake-Up Protocol

This is how messages sent to offline agents wake them up:

```
WAKE-UP SEQUENCE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Agent A (Architect) sends message to Agent B (QA), who is offline:
   AgentMessage {
     to: Agent("qa-agent-01"),
     payload: WakeUp { reason: "Tests needed for auth module" },
   }

2. Conductor receives the message:
   â†’ Checks agent_registry: qa-agent-01 status = OFFLINE
   â†’ Stores message in message_queue (SQLite, persistent)
   â†’ Checks wake_policy for qa-agent-01:

3. Wake Policy decides whether to wake:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ WakePolicy {                            â”‚
   â”‚   auto_wake: true,                      â”‚
   â”‚   wake_on_priority: Priority::Normal,   â”‚ // wake for normal+ priority
   â”‚   wake_on_channels: [Direct, Team],     â”‚ // wake for direct or team msgs
   â”‚   cooldown: Duration::minutes(5),       â”‚ // don't wake more than once per 5 min
   â”‚   max_concurrent_agents: 5,             â”‚ // don't exceed 5 running agents
   â”‚   resource_check: true,                 â”‚ // check GPU/RAM before waking
   â”‚ }                                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. If policy allows, Conductor wakes the agent:
   â†’ Spawns agent process (or activates agent within goosed)
   â†’ Waits for health check
   â†’ Delivers queued messages in order
   â†’ Agent processes messages and responds

5. If policy denies, message stays queued:
   â†’ Agent will receive it next time it comes online
   â†’ Conductor can notify sender: "QA agent offline, message queued"
   â†’ If message has expires_at and it passes, message is discarded + sender notified
```

### 4.4 Agent Self-Improvement of the Chat System

Here's the key insight: once agents are online, they can improve the communication system itself.

```
HOW AGENTS UPGRADE THEIR OWN CHAT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

The inter-agent chat system is defined by:
  1. Message types (Rust enum)
  2. Routing logic (Conductor)
  3. Serialization format (serde JSON)
  4. UI rendering (React component)

Agents CAN self-modify #4 (the UI) and add new Custom payloads.
Agents CANNOT modify #1-#3 without a full rebuild cycle.

But here's the trick:

The Custom { event_type, data } variant is a generic escape hatch.
Agents can define NEW message types at runtime by agreeing on a
custom event_type string and data schema.

Example:
  â€¢ Architect agent creates a new review protocol
  â€¢ Sends a Custom message to all agents:
    { event_type: "protocol_announcement",
      data: { protocol: "code_review_v2",
              schema: { ... },
              description: "New structured review format" }}
  â€¢ Developer agent receives it, stores the schema
  â€¢ Next code review uses the new protocol

For deeper changes (new routing, new priority levels):
  â€¢ Agent creates an ImprovementPlan targeting message_bus.rs
  â€¢ Goes through the full self-improvement pipeline (sandbox â†’ test â†’ deploy)
  â€¢ The system rebuilds, Conductor hot-swaps, agents resume
  â€¢ Now the message bus has the new capability

This means the agents evolve their own communication organically,
starting with quick runtime changes (Custom payloads) and escalating
to structural changes (self-improve + rebuild) when needed.
```

### 4.5 Chat System UI for Agents

```
AGENT CHAT PANEL (new panel for the sidebar):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT COMMUNICATIONS                    [Filter â–¼]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  #team-general                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ—ï¸ Architect [14:23]                        â”‚   â”‚
â”‚  â”‚ Plan approved for auth module. Developer    â”‚   â”‚
â”‚  â”‚ and QA, please check your task assignments. â”‚   â”‚
â”‚  â”‚                                              â”‚   â”‚
â”‚  â”‚ ğŸ’» Developer [14:23]                         â”‚   â”‚
â”‚  â”‚ Acknowledged. Starting implementation.       â”‚   â”‚
â”‚  â”‚ ETA: 3 minutes for JWT middleware.           â”‚   â”‚
â”‚  â”‚                                              â”‚   â”‚
â”‚  â”‚ âœ… QA [14:24] (woke up for this)            â”‚   â”‚
â”‚  â”‚ Online. Ready for test execution when code   â”‚   â”‚
â”‚  â”‚ is committed.                                â”‚   â”‚
â”‚  â”‚                                              â”‚   â”‚
â”‚  â”‚ ğŸ’» Developer [14:27]                         â”‚   â”‚
â”‚  â”‚ Code committed. 3 files changed:             â”‚   â”‚
â”‚  â”‚ â€¢ src/middleware/jwt.ts (new)                â”‚   â”‚
â”‚  â”‚ â€¢ src/routes/auth.ts (modified)             â”‚   â”‚
â”‚  â”‚ â€¢ package.json (1 new dep)                  â”‚   â”‚
â”‚  â”‚ @QA ready for testing.                      â”‚   â”‚
â”‚  â”‚                                              â”‚   â”‚
â”‚  â”‚ âœ… QA [14:27]                               â”‚   â”‚
â”‚  â”‚ Running test suite... 12/12 passed. âœ…       â”‚   â”‚
â”‚  â”‚ Coverage: 89%. No regressions detected.     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â”‚  ğŸ“© QUEUED (2 messages for offline agents)          â”‚
â”‚  â”œâ”€ â†’ ğŸ›¡ï¸ Security: "Review auth module" (queued)  â”‚
â”‚  â””â”€ â†’ ğŸš€ Deploy: "Stage auth for preview" (queued)â”‚
â”‚                                                     â”‚
â”‚  [View Direct Messages] [View System Log]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  You can also send messages to agents:              â”‚
â”‚  [@Agent] [Message...]                    [Send]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The user can:
â€¢ Read all agent-to-agent messages in real-time
â€¢ Filter by channel (team, direct, system)
â€¢ Send messages to specific agents or broadcast
â€¢ See queued messages for offline agents
â€¢ Wake up agents manually by clicking their status
â€¢ View conversation threads
```

---

## 5. COMPLETE ARCHITECTURE â€” Everything Wired Together

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SUPER-GOOSE AGENTIC ARCHITECTURE                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘
â•‘  â”‚ LAYER 0: CONDUCTOR (system service â€” never rebuilt by agent) â”‚     â•‘
â•‘  â”‚                                                               â”‚     â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â•‘
â•‘  â”‚  â”‚ Child     â”‚ â”‚ Health    â”‚ â”‚ Message   â”‚ â”‚ State      â”‚ â”‚     â•‘
â•‘  â”‚  â”‚ Manager   â”‚ â”‚ Checker   â”‚ â”‚ Bus       â”‚ â”‚ Store      â”‚ â”‚     â•‘
â•‘  â”‚  â”‚           â”‚ â”‚ (5s loop) â”‚ â”‚ (pub/sub) â”‚ â”‚ (SQLite)   â”‚ â”‚     â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚     â•‘
â•‘  â”‚        â”‚              â”‚              â”‚               â”‚        â”‚     â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”‚     â•‘
â•‘  â”‚  â”‚                   IPC Socket                            â”‚  â”‚     â•‘
â•‘  â”‚  â”‚  (Unix socket on Linux/Mac, Named pipe on Windows)     â”‚  â”‚     â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘
â•‘                          â”‚                                             â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘
â•‘            â–¼             â–¼             â–¼                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â•‘
â•‘  â”‚ LAYER 1:    â”‚ â”‚ LAYER 1b:  â”‚ â”‚ LAYER 2:         â”‚                 â•‘
â•‘  â”‚ goosed      â”‚ â”‚ Agent      â”‚ â”‚ Electron GUI     â”‚                 â•‘
â•‘  â”‚ (Rust)      â”‚ â”‚ Processes  â”‚ â”‚ (React/TS)       â”‚                 â•‘
â•‘  â”‚             â”‚ â”‚            â”‚ â”‚                    â”‚                 â•‘
â•‘  â”‚ Main backendâ”‚ â”‚ Each agent â”‚ â”‚ Mission Control   â”‚                 â•‘
â•‘  â”‚ LLM calls   â”‚ â”‚ can be its â”‚ â”‚ Agent Chat Panel â”‚                 â•‘
â•‘  â”‚ MCP tools   â”‚ â”‚ own processâ”‚ â”‚ Plan Viewer      â”‚                 â•‘
â•‘  â”‚ API server  â”‚ â”‚ or a threadâ”‚ â”‚ All 8+ panels    â”‚                 â•‘
â•‘  â”‚ OTA engine  â”‚ â”‚ in goosed  â”‚ â”‚                    â”‚                 â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â•‘
â•‘         â”‚              â”‚                  â”‚                            â•‘
â•‘         â”‚    Agent-to-Agent Messages      â”‚                            â•‘
â•‘         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                           â•‘
â•‘         â”‚              â”‚                  â”‚                            â•‘
â•‘         â–¼              â–¼                  â”‚                            â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                            â•‘
â•‘  â”‚ SHARED RESOURCES         â”‚            â”‚                            â•‘
â•‘  â”‚ â€¢ SQLite (WAL mode)      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â•‘
â•‘  â”‚ â€¢ ExperienceStore        â”‚                                         â•‘
â•‘  â”‚ â€¢ SkillLibrary           â”‚                                         â•‘
â•‘  â”‚ â€¢ TimeWarp EventStore    â”‚                                         â•‘
â•‘  â”‚ â€¢ team_memories table    â”‚  â† NEW: shared agent memory            â•‘
â•‘  â”‚ â€¢ message_queue table    â”‚  â† NEW: persistent message queue       â•‘
â•‘  â”‚ â€¢ agent_registry table   â”‚  â† NEW: who's online/offline           â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 6. NEW DATABASE TABLES NEEDED

```sql
-- Agent registry: tracks all known agents and their status
CREATE TABLE agent_registry (
    id TEXT PRIMARY KEY,           -- unique agent ID
    role TEXT NOT NULL,            -- architect, developer, qa, security, deploy, custom
    display_name TEXT NOT NULL,
    model_backend TEXT,            -- claude-opus, qwen3-32b, glm-4.7, ollama, etc.
    status TEXT DEFAULT 'offline', -- online, offline, busy, error, maintenance
    capabilities TEXT,             -- JSON array of capabilities
    wake_policy TEXT,              -- JSON WakePolicy config
    last_heartbeat TIMESTAMP,
    last_online TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    metadata TEXT                  -- JSON for extensibility
);

-- Persistent message queue: survives restarts
CREATE TABLE message_queue (
    id TEXT PRIMARY KEY,
    from_agent TEXT NOT NULL,
    to_target TEXT NOT NULL,       -- agent ID, role name, "broadcast", or topic
    target_type TEXT NOT NULL,     -- agent, role, team, broadcast, topic
    channel TEXT DEFAULT 'team',   -- direct, team, broadcast, system
    priority INTEGER DEFAULT 2,   -- 0=critical, 1=high, 2=normal, 3=low
    payload TEXT NOT NULL,         -- JSON AgentMessage payload
    reply_to TEXT,                 -- message ID this replies to
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP,
    delivered BOOLEAN DEFAULT FALSE,
    delivered_at TIMESTAMP,
    acknowledged BOOLEAN DEFAULT FALSE,
    acknowledged_at TIMESTAMP,
    FOREIGN KEY (from_agent) REFERENCES agent_registry(id)
);

-- Shared team memory: agents can read/write shared knowledge
CREATE TABLE team_memories (
    id TEXT PRIMARY KEY,
    namespace TEXT NOT NULL,       -- 'shared', 'team-alpha', or agent-specific
    key TEXT NOT NULL,
    value TEXT NOT NULL,           -- JSON value
    created_by TEXT NOT NULL,      -- agent ID
    updated_by TEXT,
    version INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP,
    UNIQUE(namespace, key)
);

-- Topic subscriptions for pub/sub
CREATE TABLE topic_subscriptions (
    agent_id TEXT NOT NULL,
    topic TEXT NOT NULL,
    subscribed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (agent_id, topic),
    FOREIGN KEY (agent_id) REFERENCES agent_registry(id)
);

-- Task persistence: survives rebuilds
CREATE TABLE task_queue (
    id TEXT PRIMARY KEY,
    assigned_to TEXT,              -- agent ID or NULL (unassigned)
    title TEXT NOT NULL,
    description TEXT,
    priority INTEGER DEFAULT 2,
    status TEXT DEFAULT 'pending', -- pending, assigned, running, completed, failed, cancelled
    dependencies TEXT,             -- JSON array of task IDs that must complete first
    result TEXT,                   -- JSON result when completed
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_by TEXT,               -- agent or user
    metadata TEXT                  -- JSON for extensibility
);

-- Build history: track all self-update attempts
CREATE TABLE build_history (
    id TEXT PRIMARY KEY,
    version TEXT NOT NULL,
    improvement_plan TEXT,         -- JSON ImprovementPlan
    build_status TEXT NOT NULL,    -- building, testing, swapping, completed, failed, rolled_back
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    test_results TEXT,             -- JSON TestSuiteResult
    health_check_result TEXT,      -- JSON HealthReport
    rollback_reason TEXT,
    triggered_by TEXT              -- agent ID or 'scheduler' or 'user'
);

CREATE INDEX idx_messages_undelivered ON message_queue(to_target, delivered) WHERE delivered = FALSE;
CREATE INDEX idx_messages_target_type ON message_queue(target_type, to_target, delivered);
CREATE INDEX idx_tasks_status ON task_queue(status, priority);
CREATE INDEX idx_agent_status ON agent_registry(status);
CREATE INDEX idx_team_memories_ns ON team_memories(namespace, key);
```

---

## 7. FAILSAFE ARCHITECTURE â€” What Happens When Things Go Wrong

### 7.1 Failure Modes and Recovery

| Failure | Detection | Recovery | Downtime |
|---------|-----------|----------|----------|
| **goosed crashes** | Conductor health check (5s) | Conductor restarts goosed, loads saved state | ~5s |
| **Electron crashes** | Conductor health check | Conductor restarts Electron, reconnects to goosed | ~3s |
| **Build fails** | TestRunner reports failure | Discard staging dir, continue with current binary, log failure, exponential backoff | 0s |
| **New binary fails health check** | HealthChecker on port 3285 | Don't swap â€” discard new binary, log reason | 0s |
| **New binary crashes on startup** | Conductor can't health-check 3284 | Rollback: restore backup binary, restart | ~10s |
| **Conductor crashes** | OS service manager (systemd/nssm) | OS restarts Conductor, Conductor restarts children | ~5s |
| **Database corrupted** | SQLite integrity check | Restore from WAL checkpoint or last backup | ~10s |
| **All agents stuck in loop** | Failsafe CircuitBreaker | Trip breaker, stop all non-essential agents, alert user | 0s |
| **LLM provider down** | API timeout (30s) | Fallback to local model (Ollama/LM Studio), queue cloud tasks | 0s |
| **Disk full** | Pre-build check | Skip build, alert user, suggest cleanup | 0s |
| **GPU OOM** | CUDA error detection | Reduce batch size, offload to CPU, or queue task | 0s |

### 7.2 Circuit Breaker Configuration

```rust
// Already exists in crates/goose/src/autonomous/failsafe.rs
// but needs to be extended for the Conductor layer

CircuitBreaker {
    // Build failures
    build_failures: { threshold: 3, timeout: Duration::hours(1) },
    // Agent crashes
    agent_crashes: { threshold: 5, timeout: Duration::minutes(30) },
    // LLM API errors
    llm_errors: { threshold: 10, timeout: Duration::minutes(5) },
    // Message bus overflow
    message_overflow: { threshold: 10_000, action: DropLowPriority },
    // Cost runaway
    cost_limit: { per_hour: 5.0, per_day: 50.0, action: PauseNonCritical },
}
```

### 7.3 The "Always Connected" Guarantee

```
The Conductor ensures something is ALWAYS running:

  1. Conductor starts on boot (system service)
  2. Conductor starts goosed
  3. Conductor starts Electron (if GUI mode)
  4. Conductor monitors both via health checks
  5. If goosed dies â†’ restart immediately
  6. If build requested â†’ build in background, swap only when safe
  7. If swap fails â†’ rollback to backup
  8. If rollback fails â†’ start most recent known-good binary
  9. If ALL binaries fail â†’ Conductor enters SAFE MODE:
     â†’ Start minimal HTTP server on port 3284
     â†’ Serve diagnostic page
     â†’ Accept user commands to download new binary
     â†’ Log everything for debugging

  There is ALWAYS a process accepting connections on port 3284.
  There is ALWAYS a way for the user to interact.
  There is ALWAYS a way to recover.
```

---

## 8. IMPLEMENTATION PRIORITY â€” What to Build First

### Phase 0: IMMEDIATE (Do Today)

1. **Commit 38 uncommitted files** â€” `git add -A && git commit && git push`
2. **Hide "Coming Soon" studios** â€” Replace with `experimental: true` flag

### Phase 1: Conductor Foundation (Week 1)

1. **Create `goose-conductor` crate** (~500 lines)
   - Child process manager (start/stop/restart goosed + Electron)
   - Health checker (HTTP ping every 5s)
   - IPC socket (Unix socket / Named pipe)
   - Basic state persistence (SQLite)

2. **Create database tables** (agent_registry, message_queue, task_queue, team_memories)

3. **Modify goosed** to:
   - Register with Conductor on startup
   - Accept "drain and shutdown" command
   - Serialize/restore session state

### Phase 2: Agent Message Bus (Week 2)

1. **Implement AgentMessage types** in `crates/goose/src/agent_bus/`
2. **Implement message routing** in Conductor
3. **Implement agent_registry** â€” online/offline tracking
4. **Implement wake-up protocol** â€” Conductor spawns agents on demand
5. **Wire to goose-server API** â€” new routes:
   - `POST /api/agents/{id}/message` â€” send message
   - `GET /api/agents/{id}/messages` â€” get inbox
   - `GET /api/agents/registry` â€” list all agents
   - `POST /api/agents/{id}/wake` â€” wake offline agent
   - `GET /api/agents/chat/stream` â€” SSE stream of all messages

### Phase 3: Agent Chat UI (Week 3)

1. **New AgentChatPanel.tsx** in sidebar
2. **Wire to SSE stream** â€” real-time message display
3. **User can send messages** to agents
4. **Queued messages visible** for offline agents
5. **Wake-up button** for offline agents

### Phase 4: Self-Update Pipeline (Week 4)

1. **Implement staging directory** build system
2. **Implement parallel binary testing** (port 3285)
3. **Implement Conductor-orchestrated hot-swap**
4. **Implement automatic rollback**
5. **Wire to UI** â€” progress indicator during upgrades

### Phase 5: Wire Existing Gaps (Weeks 5-6)

1. Wire Conscious backend routes (Fix 1 from NEXT-RELEASE-FIXES.md)
2. Wire AG-UI POST endpoints (Fix 3)
3. GPU Jobs backend (Fix 5)
4. Install external dependencies script (Fix 2)
5. API Key vault (Fix 7)

### Phase 6: Full Agentic Team (Weeks 7-8)

1. **HyperAgent message bus pattern** integration
2. **Zoekt code search** integration
3. **Shared memory** â€” team_memories table + API
4. **Agent self-spawning** with resource checks
5. **ALMAS role assignment** with dynamic team composition

---

## 9. WHAT MAKES THIS "MOST AGENTIC POSSIBLE"

| Feature | How It's Agentic |
|---------|-----------------|
| **Conductor** | System never fully stops. Something is always running, always accepting commands. |
| **Message Bus** | Agents communicate without human mediation. Architect assigns tasks, Developer implements, QA tests â€” all autonomously. |
| **Wake-Up Protocol** | Offline agents get woken up when needed. No human has to start them. |
| **Shared Memory** | All agents see the same project context. Architect's plan is Developer's roadmap is QA's checklist. |
| **Self-Update** | Agent improves its own code, builds itself, swaps binaries, verifies health â€” all without human intervention. |
| **Persistent Tasks** | Tasks survive crashes and restarts. Nothing is lost. Agent resumes from exactly where it stopped. |
| **Circuit Breakers** | Agent can't get stuck in infinite loops. Automatic failsafes prevent runaway costs and resource exhaustion. |
| **Agent Chat** | Agents define and evolve their own communication protocols via Custom message payloads. |
| **Rollback** | If agent makes itself worse, automatic rollback to the last known-good state. |
| **Exponential Backoff** | Failed improvements don't retry immediately. System learns from failures. |
| **User Override** | User can always intervene: KILL button, pause, manual rollback, send messages to agents. |
| **Audit Trail** | Every action, every message, every build, every decision logged permanently in SQLite. |

---

## 10. FILES TO CREATE â€” Complete Manifest

```
NEW FILES (by creation order):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Conductor crate
crates/goose-conductor/Cargo.toml
crates/goose-conductor/src/main.rs
crates/goose-conductor/src/child_manager.rs
crates/goose-conductor/src/health_checker.rs
crates/goose-conductor/src/ipc_server.rs
crates/goose-conductor/src/state_store.rs
crates/goose-conductor/src/message_bus.rs
crates/goose-conductor/src/log_manager.rs
crates/goose-conductor/src/config.rs

# Agent bus (in core goose crate)
crates/goose/src/agent_bus/mod.rs
crates/goose/src/agent_bus/messages.rs
crates/goose/src/agent_bus/registry.rs
crates/goose/src/agent_bus/router.rs
crates/goose/src/agent_bus/wake_policy.rs
crates/goose/src/agent_bus/shared_memory.rs

# API routes
crates/goose-server/src/routes/agents_api.rs
crates/goose-server/src/routes/chat_api.rs
crates/goose-server/src/routes/conductor_api.rs

# Frontend
ui/desktop/src/components/super/AgentChatPanel.tsx
ui/desktop/src/components/super/AgentRegistryPanel.tsx
ui/desktop/src/hooks/useAgentChat.ts
ui/desktop/src/hooks/useConductorStatus.ts

# Database migrations
crates/goose/migrations/007_agent_bus.sql
crates/goose-conductor/migrations/001_conductor_state.sql

# Scripts
scripts/install-conductor.ps1    (and .sh)
scripts/start-conductor.ps1      (and .sh)
scripts/conductor-status.ps1     (and .sh)

# Tests
crates/goose-conductor/tests/integration_tests.rs
crates/goose/tests/agent_bus_tests.rs

# Docs
docs/CONDUCTOR.md
docs/AGENT_COMMUNICATION.md
docs/SELF_UPDATE_ARCHITECTURE.md

TOTAL: ~40 new files, ~5,000-8,000 lines
```

---

## APPENDIX A: Comparison With Your Original Idea

Your original idea:
> "having issues with self updating its own codebase and then rebuild project launch another session/npm run start-gui keeping other open until it works then close old session/npm run start-gui and use another"

This is actually very close to the right architecture. The key refinements:

| Your Idea | Refined Solution |
|-----------|-----------------|
| Launch another `npm run start-gui` | Launch new goosed on staging port 3285, test it, then swap |
| Keep other open until it works | Conductor keeps old goosed running until new one passes health checks |
| Close old session | Conductor sends "drain and shutdown" to old goosed, graceful exit |
| Use another that was my idea | Conductor promotes new goosed to port 3284, Electron reconnects |
| How would goose continue? | Conductor persists state (tasks, messages, sessions) in SQLite |
| What if it fails? | Automatic rollback to backup binary, exponential backoff |
| Something running that doesn't affect builds | Conductor is that something â€” ~500 lines, never rebuilt by agent |

The Conductor IS your idea, formalized into a production-safe architecture.

---

## APPENDIX B: Agent Awareness Matrix

Every agent knows about every other agent:

```
         Knows About â†’   Architect  Developer  QA    Security  Deploy  User
Architect                  self       âœ…         âœ…    âœ…        âœ…      âœ…
Developer                  âœ…         self       âœ…    âœ…        âœ…      âœ…
QA                         âœ…         âœ…         self  âœ…        âœ…      âœ…
Security                   âœ…         âœ…         âœ…    self      âœ…      âœ…
Deploy                     âœ…         âœ…         âœ…    âœ…        self    âœ…
User                       âœ…         âœ…         âœ…    âœ…        âœ…      â€”

How: Every agent queries agent_registry on startup.
     Conductor broadcasts registry changes to all online agents.
     Agents subscribe to topics relevant to their role.
     User sees everything in the Agent Chat Panel.
```

---

*This document is a living architecture spec for Super-Goose's transition from L6.5 to L10+ agentic autonomy.*
*Generated 2026-02-14 from full codebase audit of SUPER-GOOSE-docs.zip + 11 uploaded artifacts.*
